{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `PyRosetta` to score monomeric designs with an array of structure- and sequence-based scoring metrics\n",
    "\n",
    "The goal of this notebook is to give an example of a computational pipeline to analyze monomeric protein designs with `PyRosetta` with a variety of biophysical metrics, such as the number of exposed hydrophobic residues or the degree of shape complementarity between elements of secondary structure.\n",
    "\n",
    "As an example, I run this pipeline on a subset of 10 designs from [Rocklin et al., 2017, Science](http://science.sciencemag.org/content/357/6347/168), which was the initial study that used the protein-stability assay to quantitatively analyze the correlates of successful protein design.\n",
    "\n",
    "Then, as a reality check that the pipeline is working, I compare the scores computed in this pipeline with the scores from the Rocklin et al. study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import `Python` modules and `RosettaScripts` XML files and initialize directories\n",
    "\n",
    "First, I import various `Python` modules, including `PyRosetta`. I will also initialize a directory to store the results of the analysis (`./results/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found rosetta database at: /software/pyrosetta2/latest/setup/pyrosetta/database; using it....\n",
      "PyRosetta-4 2017 [Rosetta PyRosetta4.Release.python27.ubuntu 2017.50+release.34adaaf34adaaf5b1bb06259ee33056a854849cbeaf2201 2017-12-13T10:25:37] retrieved from: http://www.pyrosetta.org\n",
      "(C) Copyright Rosetta Commons Member Institutions.\n",
      "Created in JHU by Sergey Lyskov and PyRosetta Team.\n",
      "\n",
      "\n",
      "core.init: Rosetta version: PyRosetta4.Release.python27.ubuntu r162 2017.50+release.34adaaf 34adaaf5b1bb06259ee33056a854849cbeaf2201 http://www.pyrosetta.org 2017-12-13T10:25:37\n",
      "core.init: command: PyRosetta -ex1 -ex2aro -database /software/pyrosetta2/latest/setup/pyrosetta/database\n",
      "core.init: 'RNG device' seed mode, using '/dev/urandom', seed=-923907081 seed_offset=0 real_seed=-923907081\n",
      "core.init.random: RandomGenerator:init: Normal mode, seed=-923907081 RG_type=mt19937\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('scripts/')\n",
    "import glob\n",
    "import pandas\n",
    "import re\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "# Import and initialize PyRosetta\n",
    "import pyrosetta\n",
    "pyrosetta.init()\n",
    "\n",
    "# Initialize a results directory\n",
    "resultsdir = './results/'\n",
    "if not os.path.isdir(resultsdir):\n",
    "    os.makedirs(resultsdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I import the scoring protocols. The exact scoring protocols are encoded in a series of `RosettaScripts` XML files (see [this tutorial](https://www.rosettacommons.org/demos/latest/tutorials/scripting_with_rosettascripts/scripting_with_rosettascripts) if you would like more information on how these are encoded). These files are stored in the directory `./scripts/xmls/` with one XML per scoring metric. The below import reads in the contents of each file as a dictionary of the form `{metric name : string of script contents}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import `analysis_scripts`, which is a dictionary\n",
    "# of the form {metric name : script contents}\n",
    "from xmls import analysis_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a score function and the XML-encoded scoring metrics in `PyRosetta`\n",
    "\n",
    "First, I initialize a `Rosetta` score function, which is the biophysical model used to score designs based on their sequence and structure. The score function has been updated many times, meaning there are multiple different versions. We will initialize the most current variant, `beta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core.scoring.ScoreFunctionFactory: [ WARNING ] **************************************************************************\n",
      "*****************************************************\n",
      "****************************************************\n",
      "beta may be a 'beta' scorefunction, but ScoreFunctionFactory thinks the beta flags weren't set.  Your scorefunction may be garbage!\n",
      "**************************************************************************\n",
      "*****************************************************\n",
      "****************************************************\n",
      "core.scoring.etable: Starting energy table calculation\n",
      "core.scoring.etable: smooth_etable: changing atr/rep split to bottom of energy well\n",
      "core.scoring.etable: smooth_etable: spline smoothing lj etables (maxdis = 6)\n",
      "core.scoring.etable: smooth_etable: spline smoothing solvation etables (max_dis = 6)\n",
      "core.scoring.etable: Finished calculating energy tables.\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/HBPoly1D.csv\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/HBFadeIntervals.csv\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/HBEval.csv\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/DonStrength.csv\n",
      "basic.io.database: Database file opened: scoring/score_functions/hbonds/ref2015_params/AccStrength.csv\n",
      "core.chemical.GlobalResidueTypeSet: Finished initializing fa_standard residue type set.  Created 573 residue types\n",
      "core.chemical.GlobalResidueTypeSet: Total time to initialize 1.77175 seconds.\n",
      "basic.io.database: Database file opened: scoring/score_functions/rama/fd/all.ramaProb\n",
      "basic.io.database: Database file opened: scoring/score_functions/rama/fd/prepro.ramaProb\n",
      "basic.io.database: Database file opened: scoring/score_functions/omega/omega_ppdep.all.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/omega/omega_ppdep.gly.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/omega/omega_ppdep.pro.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/omega/omega_ppdep.valile.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/P_AA_pp/P_AA\n",
      "basic.io.database: Database file opened: scoring/score_functions/P_AA_pp/P_AA_n\n",
      "core.scoring.P_AA: shapovalov_lib::shap_p_aa_pp_smooth_level of 1( aka low_smooth ) got activated.\n",
      "basic.io.database: Database file opened: scoring/score_functions/P_AA_pp/shapovalov/10deg/kappa131/a20.prop\n",
      "basic.io.database: Database file opened: scoring/score_functions/bondlength_bondangle/hydroxyl_torsion_preference.txt\n",
      "core.chemical.GlobalResidueTypeSet: [ WARNING ] Could not find: '##' in pdb components files [chemical/pdb_components/components.Nov01_2017.A_to_C.cif, chemical/pdb_components/components.Nov01_2017.D_to_Z.cif]! Skipping residue...\n",
      "core.chemical.GlobalResidueTypeSet: [ WARNING ] Could not find: '##' in pdb components files [chemical/pdb_components/components.Nov01_2017.A_to_C.cif, chemical/pdb_components/components.Nov01_2017.D_to_Z.cif]! Skipping residue...\n",
      "core.chemical.GlobalResidueTypeSet: [ WARNING ] Could not find: '##' in pdb components files [chemical/pdb_components/components.Nov01_2017.A_to_C.cif, chemical/pdb_components/components.Nov01_2017.D_to_Z.cif]! Skipping residue...\n",
      "core.chemical.GlobalResidueTypeSet: [ WARNING ] Could not find: '##' in pdb components files [chemical/pdb_components/components.Nov01_2017.A_to_C.cif, chemical/pdb_components/components.Nov01_2017.D_to_Z.cif]! Skipping residue...\n",
      "core.chemical.GlobalResidueTypeSet: [ WARNING ] Could not find: '#' in pdb components files [chemical/pdb_components/components.Nov01_2017.A_to_C.cif, chemical/pdb_components/components.Nov01_2017.D_to_Z.cif]! Skipping residue...\n"
     ]
    }
   ],
   "source": [
    "# Initialize a specific score function\n",
    "scorefxn = pyrosetta.rosetta.core.scoring.ScoreFunctionFactory.create_score_function(\"beta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I initilize each of the XML-encoded scoring metrics in `PyRosetta` so that they can be used downstream to actually score the designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protocols.rosetta_scripts.RosettaScriptsParser: Generating XML Schema for rosetta_scripts...\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: ...done\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: Initializing schema validator...\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: ...done\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: Validating input script...\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: ...done\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: Parsed script:\n",
      "<ROSETTASCRIPTS>\n",
      "\t<MOVERS/>\n",
      "\t<FILTERS>\n",
      "\t\t<BuriedUnsatHbonds confidence=\"0\" jump_number=\"0\" name=\"unsat_hbond\"/>\n",
      "\t</FILTERS>\n",
      "\t<PROTOCOLS>\n",
      "\t\t<Add filter_name=\"unsat_hbond\"/>\n",
      "\t</PROTOCOLS>\n",
      "</ROSETTASCRIPTS>\n",
      "core.scoring.ScoreFunctionFactory: SCOREFUNCTION: ref2015\n",
      "core.scoring.etable: Starting energy table calculation\n",
      "core.scoring.etable: smooth_etable: changing atr/rep split to bottom of energy well\n",
      "core.scoring.etable: smooth_etable: spline smoothing lj etables (maxdis = 6)\n",
      "core.scoring.etable: smooth_etable: spline smoothing solvation etables (max_dis = 6)\n",
      "core.scoring.etable: Finished calculating energy tables.\n",
      "basic.io.database: Database file opened: scoring/score_functions/PairEPotential/pdb_pair_stats_fine\n",
      "basic.io.database: Database file opened: scoring/score_functions/InterchainPotential/interchain_env_log.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/InterchainPotential/interchain_pair_log.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/EnvPairPotential/env_log.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/EnvPairPotential/cbeta_den.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/EnvPairPotential/pair_log.txt\n",
      "basic.io.database: Database file opened: scoring/score_functions/EnvPairPotential/cenpack_log.txt\n",
      "core.scoring.ramachandran: shapovalov_lib::shap_rama_smooth_level of 4( aka highest_smooth ) got activated.\n",
      "basic.io.database: Database file opened: scoring/score_functions/rama/shapovalov/kappa25/all.ramaProb\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "protocols.simple_filters.BuriedUnsatHbondFilter: Buried Unsatisfied Hbond filter over jump number 0 with cutoff 20\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: Defined filter named \"unsat_hbond\" of type BuriedUnsatHbonds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "protocols.rosetta_scripts.ParsedProtocol: ParsedProtocol mover with the following movers and filters\n",
      "protocols.rosetta_scripts.ParsedProtocol: added mover \"NULL_MOVER\" with filter \"unsat_hbond\"\n",
      "\n",
      "\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: Generating XML Schema for rosetta_scripts...\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: ...done\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: Initializing schema validator...\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: ...done\n",
      "protocols.rosetta_scripts.RosettaScriptsParser: Validating input script...\n",
      "protocols.rosetta_scripts.XmlObjects: \n",
      "\n",
      "File: /home/benchmark/T/rosetta.Glass/_commits_/main/source/src/protocols/rosetta_scripts/RosettaScriptsParser.cc:1082\n",
      "Input rosetta scripts XML file \"XmlString (not real file)\" failed to validate against the rosetta scripts schema. Use the option -parser::output_schema <output filename> to output the schema to a file to see all valid options.\n",
      "Your XML has failed validation.  The error message below will tell you where in your XML file the error occurred.  Here's how to fix it:\n",
      "\n",
      "1) If the validation fails on something obvious, like an illegal attribute due to a spelling error (perhaps you used scorefnction instead of scorefunction), then you need to fix your XML file.\n",
      "2) If you haven’t run the XML rewriter script and this might be pre-2017 Rosetta XML, run the rewriter script (tools/xsd_xrw/rewrite_rosetta_script.py) on your input XML first.  The attribute values not being in quotes (scorefunction=talaris2014 instead of scorefunction=\"talaris2014\") is a good indicator that this is your problem.\n",
      "3) If you are a developer and neither 1 nor 2 worked - email the developer’s mailing list or try Slack.\n",
      "4) If you are an academic or commercial user - try the Rosetta Forums https://www.rosettacommons.org/forum\n",
      "5)\n",
      "\n",
      "\n",
      "Error messages were:\n",
      "From line 5:\n",
      "Error: Element 'BuriedUnsatHbonds', attribute 'report_sc_heavy_atom_unsats': The attribute 'report_sc_heavy_atom_unsats' is not allowed.\n",
      "\n",
      " 1: <ROSETTASCRIPTS>\n",
      " 2: <MOVERS>\n",
      " 3: </MOVERS>\n",
      " 4: <FILTERS>\n",
      " 5:     <BuriedUnsatHbonds name=\"new_buns_sc_heavy\" scorefxn=\"hard\" report_sc_heavy_atom_unsats=\"true\" ignore_surface_res=\"true\" residue_surface_cutoff=\"20.0\" ignore_bb_heavy_unsats=\"false\" confidence=\"0\"/>\n",
      " 6: </FILTERS>\n",
      " 7: <PROTOCOLS>\n",
      " 8:     <Add filter_name=\"new_buns_sc_heavy\" />\n",
      " 9: </PROTOCOLS>\n",
      "10: </ROSETTASCRIPTS>\n",
      "From line 5:\n",
      "Error: Element 'BuriedUnsatHbonds', attribute 'ignore_surface_res': The attribute 'ignore_surface_res' is not allowed.\n",
      "\n",
      " 1: <ROSETTASCRIPTS>\n",
      " 2: <MOVERS>\n",
      " 3: </MOVERS>\n",
      " 4: <FILTERS>\n",
      " 5:     <BuriedUnsatHbonds name=\"new_buns_sc_heavy\" scorefxn=\"hard\" report_sc_heavy_atom_unsats=\"true\" ignore_surface_res=\"true\" residue_surface_cutoff=\"20.0\" ignore_bb_heavy_unsats=\"false\" confidence=\"0\"/>\n",
      " 6: </FILTERS>\n",
      " 7: <PROTOCOLS>\n",
      " 8:     <Add filter_name=\"new_buns_sc_heavy\" />\n",
      " 9: </PROTOCOLS>\n",
      "10: </ROSETTASCRIPTS>\n",
      "From line 5:\n",
      "Error: Element 'BuriedUnsatHbonds', attribute 'residue_surface_cutoff': The attribute 'residue_surface_cutoff' is not allowed.\n",
      "\n",
      " 1: <ROSETTASCRIPTS>\n",
      " 2: <MOVERS>\n",
      " 3: </MOVERS>\n",
      " 4: <FILTERS>\n",
      " 5:     <BuriedUnsatHbonds name=\"new_buns_sc_heavy\" scorefxn=\"hard\" report_sc_heavy_atom_unsats=\"true\" ignore_surface_res=\"true\" residue_surface_cutoff=\"20.0\" ignore_bb_heavy_unsats=\"false\" confidence=\"0\"/>\n",
      " 6: </FILTERS>\n",
      " 7: <PROTOCOLS>\n",
      " 8:     <Add filter_name=\"new_buns_sc_heavy\" />\n",
      " 9: </PROTOCOLS>\n",
      "10: </ROSETTASCRIPTS>\n",
      "From line 5:\n",
      "Error: Element 'BuriedUnsatHbonds', attribute 'ignore_bb_heavy_unsats': The attribute 'ignore_bb_heavy_unsats' is not allowed.\n",
      "\n",
      " 1: <ROSETTASCRIPTS>\n",
      " 2: <MOVERS>\n",
      " 3: </MOVERS>\n",
      " 4: <FILTERS>\n",
      " 5:     <BuriedUnsatHbonds name=\"new_buns_sc_heavy\" scorefxn=\"hard\" report_sc_heavy_atom_unsats=\"true\" ignore_surface_res=\"true\" residue_surface_cutoff=\"20.0\" ignore_bb_heavy_unsats=\"false\" confidence=\"0\"/>\n",
      " 6: </FILTERS>\n",
      " 7: <PROTOCOLS>\n",
      " 8:     <Add filter_name=\"new_buns_sc_heavy\" />\n",
      " 9: </PROTOCOLS>\n",
      "10: </ROSETTASCRIPTS>\n",
      "------------------------------------------------------------\n",
      "Warning messages were:\n",
      "------------------------------------------------------------\n",
      "protocols.rosetta_scripts.XmlObjects: Error creating parsed protocol.\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 694: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/software/miniconda3/envs/pyrosetta2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/miniconda3/envs/pyrosetta2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1824\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/miniconda3/envs/pyrosetta2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1412\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/miniconda3/envs/pyrosetta2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             )\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/miniconda3/envs/pyrosetta2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1170\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/miniconda3/envs/pyrosetta2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/miniconda3/envs/pyrosetta2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# quarter of the traceback (250 frames by default) is repeats, and find the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/miniconda3/envs/pyrosetta2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mis_recursion_error\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# a recursion error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrecursion_error_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m            \u001b[0;32mand\u001b[0m \u001b[0;34m\"recursion\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 694: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# Initialize the filters by reading in and processing the XML file for each filter\n",
    "pr_filters = {\n",
    "    \n",
    "    filter_name : pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(script_contents)\n",
    "        .get_filter(filter_name)\n",
    "    for (filter_name, script_contents) in analysis_scripts.items()\n",
    "    if filter_name in ['unsat_hbond', 'new_buns_sc_heavy']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the input PDB files\n",
    "\n",
    "First I define a function, `score_pdb_file`, which uses `PyRosetta` to score an input PDB file with the above metrics.\n",
    "\n",
    "Note: You may want to parallelize the scoring step if you're running it on thousands of designs. With this in mind, I wrote `score_pdb_file` to accept a single PDB file so that it could be called many times in parallel. Let me know if you would like suggestions for how to parallelize this task. I have been using [`Jug`](https://jug.readthedocs.io/en/latest/) to do so, and would be happy to describe my strategy in greater detail if you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_pdb_file(pdb_file_name):\n",
    "    \"\"\"\n",
    "    Score an input PDB file using an array of Rosetta-based metrics\n",
    "    \n",
    "    PyRosetta computes these scores using the metrics encoded in the\n",
    "    RosettaScripts XML files in the directory `./scripts/xmls/`.\n",
    "    \n",
    "    Args:\n",
    "        `pdb_file_name` : The path to a PDB file (string)\n",
    "    \n",
    "    Returns:\n",
    "        A dataframe with scores for the PDB file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in the PDB file and convert it to a pose\n",
    "    pose = pyrosetta.pose_from_pdb(pdb_file_name)\n",
    "    \n",
    "    # Compute scores from energies from the score function and store\n",
    "    # the scores in a dictionary with the form {score name : value}\n",
    "    scores_dict = {}\n",
    "    scorefxn(pose)\n",
    "    for score in scorefxn.get_nonzero_weighted_scoretypes():\n",
    "        re_pattern = re.compile(r'ScoreType\\.(?P<score_name>\\w+)')\n",
    "        score_name = re_pattern.search(str(score)).group('score_name')\n",
    "        scores_dict[score_name] = pose.energies().total_energies()[score]\n",
    "    \n",
    "    # Compute XML-based scores and add these scores to the dictionary\n",
    "    # with all the scores\n",
    "    for (filter_name, pr_filter) in pr_filters.items():\n",
    "        scores_dict[filter_name] = pr_filter.score(pose)\n",
    "    \n",
    "    # Conver the dictionary to a dataframe with the PDB file name as an index\n",
    "    scores_df = pandas.DataFrame.from_dict({pdb_file_name : scores_dict}, orient='index')\n",
    "    \n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I read in a test set of PDB files from the Rocklin et al. study, which are stored in the directory `./data/rocklin_rd4_examples/`. I then score each of them using the above function (this step could be parallelized). Finally, I concatenate the data into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input PDB files\n",
    "input_pdb_files = glob.glob('./data/rocklin_rd4_examples/*.pdb')\n",
    "\n",
    "# Score each PDB file one at a time\n",
    "scores_dfs = [score_pdb_file(f) for f in input_pdb_files]\n",
    "\n",
    "# Concatenate each of the PDB-specific dataframes\n",
    "test_scores = pandas.concat(scores_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I show the scores as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataframe\n",
    "test_scores['PDB_name'] = test_scores.index.map(lambda x: os.path.basename(x))\n",
    "test_scores.set_index('PDB_name', inplace=True)\n",
    "test_scores_outfile = os.path.join(resultsdir, 'scores.csv')\n",
    "test_scores.to_csv(test_scores_outfile, index_label='PDB_name')\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the scores computed above to the scores computed in the Rocklin et al. study, just to make sure our scoring pipeline gives similar results\n",
    "\n",
    "First, I read in scores for these structures taken from the Rocklin et al. study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocklin_scores_f = './data/Rocklin_rd4_relax_scored_filtered_betanov15.sc'\n",
    "rocklin_scores = pandas.read_csv('./data/Rocklin_rd4_relax_scored_filtered_betanov15.sc', sep='\\t')\n",
    "rocklin_scores.set_index('description', inplace=True)\n",
    "del rocklin_scores['SCORE:'] # non-informative line, is 'SCORE:' in all entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I compute the correlation between our scores and the Rockclin scores for each metric. Almost all metrics are highly correlated with the Rocklin et al. study. A few metrics could not be correlated (i.e., R = `NaN`). As shown in the below correlation plots, that is because all designs have the exact same score in both scoring protocols, so there is no spead in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an ordered list of design PDB file names to compare\n",
    "pdbs = list(test_scores.index.values)\n",
    "\n",
    "# Compute the correlation between our scores and the Rocklin scores for each design\n",
    "corr_d = {}\n",
    "corr_cutoff = 0.95\n",
    "metrics_below_corr_cutoff = []\n",
    "metrics_not_in_rocklin_scores = []\n",
    "metrics_with_corr_NaN = []\n",
    "ignore_metrics = ['sequence', 'description', 'dssp']\n",
    "for metric in test_scores:\n",
    "    \n",
    "    # Skip over certain non-quantitative metrics\n",
    "    if metric in ignore_metrics:\n",
    "        continue\n",
    "    \n",
    "    # Make sure the Rocklin data has the metric\n",
    "    if metric not in rocklin_scores:\n",
    "        metrics_not_in_rocklin_scores.append(metric)\n",
    "        continue\n",
    "    \n",
    "    # Correlate our score and the Rocklin score and store\n",
    "    # in a dictionary. If R = 'NaN', don't store in dict\n",
    "    (r,p) = scipy.stats.pearsonr(test_scores.loc[pdbs][metric],\n",
    "                                 rocklin_scores.loc[pdbs][metric])\n",
    "    if numpy.isnan(r):\n",
    "        metrics_with_corr_NaN.append(metric)\n",
    "        continue\n",
    "    assert metric not in corr_d\n",
    "    corr_d[metric] = {'Pearson_R':r}\n",
    "    if r < corr_cutoff:\n",
    "        metrics_below_corr_cutoff.append(metric)\n",
    "\n",
    "# Show results\n",
    "print(\"Compared the scores from {0} metrics on {1} designs\".format(\n",
    "                                                    len(corr_d),\n",
    "                                                    len(pdbs)))\n",
    "print(\"{0} metrics had R > {1}\".format(\n",
    "                                len(corr_d)-len(metrics_below_corr_cutoff),\n",
    "                                corr_cutoff))\n",
    "print(\"{0} metrics had R < {1}. They are: {2}\".format(\n",
    "                                len(metrics_below_corr_cutoff),\n",
    "                                corr_cutoff,\n",
    "                                ', '.join(metrics_below_corr_cutoff)))\n",
    "print(\"{0} metrics had R = nan. They are: {1}\".format(\n",
    "                                len(metrics_with_corr_NaN),\n",
    "                                ', '.join(metrics_with_corr_NaN)))\n",
    "print(\"{0} metrics were not in the Rocklin scores: {1}\".format(\n",
    "                                len(metrics_not_in_rocklin_scores),\n",
    "                                ', '.join(metrics_not_in_rocklin_scores)))\n",
    "\n",
    "# Show a dataframe of each metric and its correlation coefficients\n",
    "corr_df = pandas.DataFrame.from_dict(corr_d, orient=\"index\")\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I show correlation plots for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_to_plot = list(corr_d.keys()) + metrics_with_corr_NaN\n",
    "nsubplots = len(metrics_to_plot)\n",
    "ncols = 4.0\n",
    "nrows = math.ceil(nsubplots/ncols)\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "fig = plt.figure(figsize=[15,(7.5/2)*nrows])\n",
    "for (i, metric) in enumerate(metrics_to_plot, 1):\n",
    "    ax = fig.add_subplot(nrows, ncols, i)\n",
    "    xs = test_scores.loc[pdbs][metric]\n",
    "    ys = rocklin_scores.loc[pdbs][metric]\n",
    "    sns.regplot(xs, ys, ax=ax)\n",
    "    min_val = min(list(xs) + list(ys))\n",
    "    max_val = max(list(xs) + list(ys))\n",
    "    ticks = [min_val, max_val]\n",
    "    lims = [min_val-abs(0.1*min_val), max_val+abs(0.1*max_val)]\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_xlabel('Our scores')\n",
    "    ax.set_ylabel('Rocklin scores')\n",
    "    ax.set_title(metric)\n",
    "    #ax.text(0, 1, \"R = {0}\".format(round(corr_d[metric]['Pearson_R'], 2)))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyrosetta2]",
   "language": "python",
   "name": "conda-env-pyrosetta2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
